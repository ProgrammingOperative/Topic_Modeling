{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "import random\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['transcript', 'url'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/transcripts.csv')\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good morning. How are you?(Laughter)It's been ...</td>\n",
       "      <td>https://www.ted.com/talks/ken_robinson_says_sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank you so much, Chris. And it's truly a gre...</td>\n",
       "      <td>https://www.ted.com/talks/al_gore_on_averting_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Music: \"The Sound of Silence,\" Simon &amp; Garfun...</td>\n",
       "      <td>https://www.ted.com/talks/david_pogue_says_sim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you're here today — and I'm very happy that...</td>\n",
       "      <td>https://www.ted.com/talks/majora_carter_s_tale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>About 10 years ago, I took on the task to teac...</td>\n",
       "      <td>https://www.ted.com/talks/hans_rosling_shows_t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          transcript  \\\n",
       "0  Good morning. How are you?(Laughter)It's been ...   \n",
       "1  Thank you so much, Chris. And it's truly a gre...   \n",
       "2  (Music: \"The Sound of Silence,\" Simon & Garfun...   \n",
       "3  If you're here today — and I'm very happy that...   \n",
       "4  About 10 years ago, I took on the task to teac...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.ted.com/talks/ken_robinson_says_sc...  \n",
       "1  https://www.ted.com/talks/al_gore_on_averting_...  \n",
       "2  https://www.ted.com/talks/david_pogue_says_sim...  \n",
       "3  https://www.ted.com/talks/majora_carter_s_tale...  \n",
       "4  https://www.ted.com/talks/hans_rosling_shows_t...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2467 entries, 0 to 2466\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   transcript  2467 non-null   object\n",
      " 1   url         2467 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 38.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATING A VOCUBLARY FROM THE DATA USING COUNT VECTORIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2467x34029 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1108062 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "term_matrix =  count_vect.fit_transform(data['transcript'].values.astype('U')) #including words that occur less than 80% of the time in the document\n",
    "'''stop words have also been removed since they barely contribute significantly to the vocabulary'''\n",
    "term_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results above, every word in the document is represented by a 34029 dimensional vector. i.e we have a vocabulary of 34029 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(n_components=5, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(n_components=5, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LatentDirichletAllocation(n_components=5, random_state=42)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we now use LDA to create topics based on the probability of each word in the document\n",
    "lda = LatentDirichletAllocation(n_components=5, random_state=42) #we set n = 5 as our initial guess of topics in the data\n",
    "lda.fit(term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ProgrammingOperative\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "morphs\n",
      "prosecuted\n",
      "rosie\n",
      "berkeley\n",
      "dues\n",
      "promising\n",
      "450\n",
      "arising\n",
      "multimillion\n",
      "myspace\n",
      "tablet\n",
      "authoritarianism\n",
      "textile\n",
      "mountainsides\n",
      "pneumonia\n",
      "union\n",
      "collectible\n",
      "fissures\n",
      "herders\n",
      "hypocrisy\n",
      "tremendous\n",
      "converter\n",
      "emits\n",
      "apocalyptic\n",
      "researcher\n",
      "sounds\n",
      "obsidian\n",
      "claps\n",
      "stunts\n",
      "degrades\n",
      "recommended\n",
      "prisoner\n",
      "metabolic\n",
      "vitality\n",
      "l1\n",
      "shanghai\n",
      "magnifying\n",
      "mesmerizing\n",
      "materialize\n",
      "opinions\n",
      "taxonomy\n",
      "blameless\n",
      "steeper\n",
      "lick\n",
      "emerge\n",
      "gigabits\n",
      "topos\n",
      "knowhow\n",
      "login\n",
      "colic\n",
      "urging\n"
     ]
    }
   ],
   "source": [
    "#top 50 words in the vocubulary\n",
    "for i in range(51):\n",
    "    random_word = random.randint(0, len(count_vect.get_feature_names()))\n",
    "    print(count_vect.get_feature_names()[random_word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.07009199e+01, 8.75603006e+02, 3.20657303e-01, ...,\n",
       "       2.19612451e+00, 2.21755631e-01, 2.01565888e-01])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#displaying the first topic\n",
    "first_topic = lda.components_[0]\n",
    "first_topic# the output is a vector. from the vector we can then obtain the words from the count_vectorizer featu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thing\n",
      "different\n",
      "laughter\n",
      "kind\n",
      "new\n",
      "right\n",
      "look\n",
      "little\n",
      "things\n",
      "actually\n"
     ]
    }
   ],
   "source": [
    "#obtaining the top words in the first topic\n",
    "top_topic_words = first_topic.argsort()[-10:]\n",
    "for i in top_topic_words:\n",
    "    print(count_vect.get_feature_names()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic #0:\n",
      "['work', 'lot', 'light', 'got', 'earth', 'space', 'want', 'll', 'life', 'use', 'thing', 'different', 'laughter', 'kind', 'new', 'right', 'look', 'little', 'things', 'actually']\n",
      "\n",
      "\n",
      "Top 10 words for topic #1:\n",
      "['look', 'women', 'tell', 'come', 'didn', 'love', 'work', 'little', 'good', 'day', 'thing', 'did', 'got', 'things', 'right', 'life', 'say', 'want', 'said', 'laughter']\n",
      "\n",
      "\n",
      "Top 10 words for topic #2:\n",
      "['internet', 'said', 'got', 'public', 'did', 'say', 'power', 'thing', 'lot', 'today', 'country', 'government', 'need', 'right', 'work', 'things', 'actually', 'city', 'want', 'new']\n",
      "\n",
      "\n",
      "Top 10 words for topic #3:\n",
      "['want', 'actually', 'today', '000', 'use', 'carbon', 'look', 'got', 'lot', 'climate', 'change', 'fish', 'women', 'energy', 'oil', 'year', 'need', 'percent', 'water', 'food']\n",
      "\n",
      "\n",
      "Top 10 words for topic #4:\n",
      "['today', 'cells', 'good', 'let', 'right', 'work', 'problem', 'human', 'data', 'new', 'cancer', 'want', 'different', 'things', 'look', 'health', 'brain', 'need', 'percent', 'actually']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#displaying the top 20 words in each of the topics\n",
    "for i,topic in enumerate(lda.components_):\n",
    "    print(f'Top 10 words for topic #{i}:')\n",
    "    print([count_vect.get_feature_names()[i] for i in topic.argsort()[-20:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOPIC TRACKING USING NON-NEGATIVE MATRIX FACTORIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "term_matrix_tfidf = tfidf_vect.fit_transform(data['transcript'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2467x34029 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1108062 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_matrix_tfidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ProgrammingOperative\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1692: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NMF(n_components=5, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NMF</label><div class=\"sk-toggleable__content\"><pre>NMF(n_components=5, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NMF(n_components=5, random_state=42)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf = NMF(n_components=5, random_state=42)\n",
    "nmf.fit(term_matrix_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ProgrammingOperative\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uppercase\n",
      "gsm\n",
      "baptism\n",
      "kenyon\n",
      "untouchable\n",
      "matrices\n",
      "pans\n",
      "geometric\n",
      "subcontinent\n",
      "cures\n"
     ]
    }
   ],
   "source": [
    "#obtaining random words from our new vocab\n",
    "import random\n",
    "\n",
    "for i in range(10):\n",
    "    random_id = random.randint(0,len(tfidf_vect.get_feature_names()))\n",
    "    print(tfidf_vect.get_feature_names()[random_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ll\n",
      "sort\n",
      "use\n",
      "technology\n",
      "computer\n",
      "want\n",
      "light\n",
      "new\n",
      "earth\n",
      "water\n",
      "look\n",
      "thing\n",
      "space\n",
      "right\n",
      "design\n",
      "kind\n",
      "little\n",
      "laughter\n",
      "things\n",
      "actually\n"
     ]
    }
   ],
   "source": [
    "#top words in the first topic\n",
    "first_topic = nmf.components_[0]\n",
    "top_topic_words = first_topic.argsort()[-20:]\n",
    "for i in top_topic_words:\n",
    "    print(tfidf_vect.get_feature_names()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 words for topic #0:\n",
      "['ll', 'sort', 'use', 'technology', 'computer', 'want', 'light', 'new', 'earth', 'water', 'look', 'thing', 'space', 'right', 'design', 'kind', 'little', 'laughter', 'things', 'actually']\n",
      "\n",
      "\n",
      "Top 20 words for topic #1:\n",
      "['went', 'family', 'girls', 'didn', 'man', 'woman', 'did', 'got', 'want', 'day', 'children', 'love', 'say', 'kids', 'life', 'school', 'men', 'laughter', 'said', 'women']\n",
      "\n",
      "\n",
      "Top 20 words for topic #2:\n",
      "['piano', 'instrument', 'laughter', 'sounds', 'singing', 'playing', 'violin', 'musicians', 'video', 'classical', 'piece', 'hear', 'orchestra', 'ends', 'musical', 'song', 'play', 'guitar', 'sound', 'music']\n",
      "\n",
      "\n",
      "Top 20 words for topic #3:\n",
      "['today', 'business', 'economy', 'health', 'change', 'economic', 'growth', 'social', 'city', 'cities', 'money', 'china', 'dollars', 'need', 'government', 'global', 'country', 'africa', 'percent', 'countries']\n",
      "\n",
      "\n",
      "Top 20 words for topic #4:\n",
      "['medicine', 'genes', 'actually', 'dna', 'human', 'drugs', 'tumor', 'health', 'stem', 'drug', 'blood', 'patient', 'neurons', 'body', 'cell', 'patients', 'disease', 'cancer', 'cells', 'brain']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#obtaining top 20 words for each of the topics\n",
    "for i,topic in enumerate(nmf.components_):\n",
    "    print(f'Top 20 words for topic #{i}:')\n",
    "    print([tfidf_vect.get_feature_names()[i] for i in topic.argsort()[-20:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook was to attempt to find a means of identifying the main topics under a given TED TALKS transcripts. We decided to use text clustering using SKlearn's Latent DirichletAllocation and Non-negative matrix factorization. The results  show various topics discussed based on the most appearing words within them. For instance, the first topic using LDA talks about life in particular and how the little things matter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "449a2b83f2288868779268c20f9889e20ff88551a8511abea4440c64823eb5e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
